{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "f6790d92-7232-4e4e-acb7-f03197f1c037",
   "metadata": {
    "tags": []
   },
   "source": [
    "# Proyecto Final- TEXT MINING & IMAGE RECOGNITION - SECCIÓN B\n",
    "# Parte 2\n",
    "## Diego Obregon\n",
    "### 11006956"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "4c88bc6f-b14a-4005-9f7b-373f17d1bbcb",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
    "from tensorflow.keras import layers\n",
    "from tensorflow.keras import models\n",
    "from tensorflow.keras.callbacks import EarlyStopping\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7cb298c4-935b-40eb-b883-797d24c2909c",
   "metadata": {},
   "source": [
    "# Arquitectura 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "d8d6cafb-f9f9-4e08-a2aa-245aaeb57079",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def create_model_1():\n",
    "    model = models.Sequential()\n",
    "    model.add(layers.Conv2D(32, (3, 3), activation='relu', input_shape=(32, 32, 3)))\n",
    "    model.add(layers.MaxPooling2D((2, 2)))\n",
    "    model.add(layers.Conv2D(64, (3, 3), activation='relu'))\n",
    "    model.add(layers.MaxPooling2D((2, 2)))\n",
    "    model.add(layers.Flatten())\n",
    "    model.add(layers.Dense(64, activation='relu'))\n",
    "    model.add(layers.Dense(6, activation='softmax'))  # 6 clases en total\n",
    "    \n",
    "    model.compile(optimizer='adam',\n",
    "                  loss='categorical_crossentropy',\n",
    "                  metrics=['accuracy'])\n",
    "    return model"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "02d119aa-d86a-495f-b7c1-6837b584c771",
   "metadata": {},
   "source": [
    "# Arquitectura 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "96c09833-8afa-4f16-882a-c78d4057d582",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def create_model_2():\n",
    "    model = models.Sequential()\n",
    "    model.add(layers.Conv2D(32, (3, 3), activation='relu', input_shape=(32, 32, 3)))\n",
    "    model.add(layers.MaxPooling2D((2, 2)))\n",
    "    model.add(layers.Conv2D(64, (3, 3), activation='relu'))\n",
    "    model.add(layers.MaxPooling2D((2, 2)))\n",
    "    model.add(layers.Conv2D(128, (3, 3), activation='relu'))\n",
    "    model.add(layers.MaxPooling2D((2, 2)))\n",
    "    model.add(layers.Flatten())\n",
    "    model.add(layers.Dense(128, activation='relu'))\n",
    "    model.add(layers.Dense(6, activation='softmax'))\n",
    "    \n",
    "    model.compile(optimizer='adam',\n",
    "                  loss='categorical_crossentropy',\n",
    "                  metrics=['accuracy'])\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "2d352a59-e406-41cd-9c2c-1ecb23b78655",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Arquitectura 3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "c7dbca2b-e45f-4bdb-be48-ad97c6e296aa",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def create_model_3():\n",
    "    model = models.Sequential()\n",
    "    model.add(layers.Conv2D(32, (3, 3), activation='relu', input_shape=(32, 32, 3)))\n",
    "    model.add(layers.MaxPooling2D((2, 2)))\n",
    "    model.add(layers.Conv2D(64, (3, 3), activation='relu'))\n",
    "    model.add(layers.MaxPooling2D((2, 2)))\n",
    "    model.add(layers.Conv2D(128, (3, 3), activation='relu'))\n",
    "    model.add(layers.MaxPooling2D((2, 2)))\n",
    "    model.add(layers.Flatten())\n",
    "    model.add(layers.Dense(128, activation='relu'))\n",
    "    model.add(layers.Dropout(0.5))  # Añadir Dropout para evitar sobreajuste\n",
    "    model.add(layers.Dense(6, activation='softmax'))\n",
    "    \n",
    "    model.compile(optimizer='adam',\n",
    "                  loss='categorical_crossentropy',\n",
    "                  metrics=['accuracy'])\n",
    "    return model\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "b174e404-ac9c-4900-a92e-21b33cfbfb3d",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "train_datagen = ImageDataGenerator(\n",
    "    rescale=1./255, \n",
    "    rotation_range=40,\n",
    "    width_shift_range=0.2,\n",
    "    height_shift_range=0.2,\n",
    "    shear_range=0.2,\n",
    "    zoom_range=0.2,\n",
    "    horizontal_flip=True,\n",
    "    fill_mode='nearest' )\n",
    "\n",
    "validation_datagen = ImageDataGenerator(rescale=1./255)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f8520454-1c40-4949-bc34-6a5fb532f541",
   "metadata": {},
   "source": [
    "# Conjunto de entrenamiento"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "8094e70c-3aed-4229-a5bb-ce0339ff0bf6",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 2572 images belonging to 6 classes.\n"
     ]
    }
   ],
   "source": [
    "train_generator = train_datagen.flow_from_directory(\n",
    "    'data_Image/train',\n",
    "    target_size=(32, 32),\n",
    "    batch_size=32,\n",
    "    class_mode='categorical')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "af67761b-7ff2-4582-ba42-c514c7247a5e",
   "metadata": {},
   "source": [
    "# Conjunto de validación\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "88eb3e6b-27b0-4524-a1f2-5a39c55c5307",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 1106 images belonging to 6 classes.\n"
     ]
    }
   ],
   "source": [
    "validation_generator = validation_datagen.flow_from_directory(\n",
    "    'data_Image/validation',\n",
    "    target_size=(32, 32),\n",
    "    batch_size=32,\n",
    "    class_mode='categorical')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "005a4fdb-80e3-42d2-af1c-5ed23318ceae",
   "metadata": {},
   "source": [
    "# CNN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "0520e809-11e0-4992-a5f7-7c3a57c0a1ca",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\USUARIO\\anaconda3\\Lib\\site-packages\\keras\\src\\layers\\convolutional\\base_conv.py:107: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
      "  super().__init__(activity_regularizer=activity_regularizer, **kwargs)\n"
     ]
    }
   ],
   "source": [
    "model = models.Sequential()\n",
    "\n",
    "model.add(layers.Conv2D(32, (3, 3), activation='relu', input_shape=(32, 32, 3)))\n",
    "model.add(layers.MaxPooling2D((2, 2)))\n",
    "\n",
    "model.add(layers.Conv2D(64, (3, 3), activation='relu'))\n",
    "model.add(layers.MaxPooling2D((2, 2)))\n",
    "\n",
    "model.add(layers.Flatten())\n",
    "model.add(layers.Dense(128, activation='relu'))\n",
    "model.add(layers.Dense(6, activation='softmax'))\n",
    "\n",
    "model.compile(optimizer='adam', loss='categorical_crossentropy', metrics=['accuracy'])\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0af7d6ba-3492-41b5-aa6d-def11669926c",
   "metadata": {},
   "source": [
    "# Entrenar el modelo"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "f57cf5be-68a8-4ecb-b650-548890e03691",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\USUARIO\\anaconda3\\Lib\\site-packages\\keras\\src\\trainers\\data_adapters\\py_dataset_adapter.py:122: UserWarning: Your `PyDataset` class should call `super().__init__(**kwargs)` in its constructor. `**kwargs` can include `workers`, `use_multiprocessing`, `max_queue_size`. Do not pass these arguments to `fit()`, as they will be ignored.\n",
      "  self._warn_if_super_not_called()\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m 78/100\u001b[0m \u001b[32m━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━\u001b[0m \u001b[1m8s\u001b[0m 370ms/step - accuracy: 0.3457 - loss: 1.5790 "
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\USUARIO\\anaconda3\\Lib\\contextlib.py:155: UserWarning: Your input ran out of data; interrupting training. Make sure that your dataset or generator can generate at least `steps_per_epoch * epochs` batches. You may need to use the `.repeat()` function when building your dataset.\n",
      "  self.gen.throw(typ, value, traceback)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m100/100\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m47s\u001b[0m 419ms/step - accuracy: 0.3681 - loss: 1.5363 - val_accuracy: 0.6383 - val_loss: 0.9560\n",
      "Epoch 2/10\n",
      "\u001b[1m100/100\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m37s\u001b[0m 349ms/step - accuracy: 0.6272 - loss: 0.9743 - val_accuracy: 0.7342 - val_loss: 0.7651\n",
      "Epoch 3/10\n",
      "\u001b[1m100/100\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m36s\u001b[0m 333ms/step - accuracy: 0.6746 - loss: 0.8618 - val_accuracy: 0.6971 - val_loss: 0.8369\n",
      "Epoch 4/10\n",
      "\u001b[1m100/100\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m34s\u001b[0m 305ms/step - accuracy: 0.7234 - loss: 0.7383 - val_accuracy: 0.7703 - val_loss: 0.6660\n",
      "Epoch 5/10\n",
      "\u001b[1m100/100\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m35s\u001b[0m 321ms/step - accuracy: 0.7442 - loss: 0.6771 - val_accuracy: 0.7848 - val_loss: 0.6690\n",
      "Epoch 6/10\n",
      "\u001b[1m100/100\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m32s\u001b[0m 303ms/step - accuracy: 0.7959 - loss: 0.5859 - val_accuracy: 0.6980 - val_loss: 0.8514\n",
      "Epoch 7/10\n",
      "\u001b[1m100/100\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m33s\u001b[0m 314ms/step - accuracy: 0.7871 - loss: 0.5844 - val_accuracy: 0.8662 - val_loss: 0.4146\n",
      "Epoch 8/10\n",
      "\u001b[1m100/100\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m34s\u001b[0m 332ms/step - accuracy: 0.8092 - loss: 0.5024 - val_accuracy: 0.8472 - val_loss: 0.4371\n",
      "Epoch 9/10\n",
      "\u001b[1m100/100\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m33s\u001b[0m 299ms/step - accuracy: 0.8409 - loss: 0.4205 - val_accuracy: 0.8761 - val_loss: 0.3800\n",
      "Epoch 10/10\n",
      "\u001b[1m100/100\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m34s\u001b[0m 324ms/step - accuracy: 0.8556 - loss: 0.4007 - val_accuracy: 0.8770 - val_loss: 0.3815\n"
     ]
    }
   ],
   "source": [
    "early_stopping = EarlyStopping(monitor='val_loss', patience=3, restore_best_weights=True)\n",
    "\n",
    "history = model.fit(\n",
    "    train_generator,\n",
    "    steps_per_epoch=100,\n",
    "    epochs=10,\n",
    "    validation_data=validation_generator,\n",
    "    validation_steps=50,\n",
    "    callbacks=[early_stopping] )"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "aef4ac25-e326-4fcd-bbd7-7855b3e24e4d",
   "metadata": {},
   "source": [
    "# Entrenar y evaluar Modelo 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "b0ff2532-b134-4a9f-aa08-82a85375cf93",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\USUARIO\\anaconda3\\Lib\\site-packages\\keras\\src\\layers\\convolutional\\base_conv.py:107: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
      "  super().__init__(activity_regularizer=activity_regularizer, **kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "\u001b[1m81/81\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m43s\u001b[0m 460ms/step - accuracy: 0.2893 - loss: 1.6614 - val_accuracy: 0.4286 - val_loss: 1.4363\n",
      "Epoch 2/10\n",
      "\u001b[1m81/81\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m38s\u001b[0m 432ms/step - accuracy: 0.5309 - loss: 1.1941 - val_accuracy: 0.6257 - val_loss: 1.0534\n",
      "Epoch 3/10\n",
      "\u001b[1m81/81\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m40s\u001b[0m 467ms/step - accuracy: 0.6351 - loss: 0.9534 - val_accuracy: 0.7315 - val_loss: 0.7794\n",
      "\u001b[1m35/35\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 270ms/step - accuracy: 0.4327 - loss: 1.4195\n",
      "Model 1 Accuracy: 0.4285714328289032\n"
     ]
    }
   ],
   "source": [
    "model_1 = create_model_1()\n",
    "history_1 = model_1.fit(train_generator, epochs=10, validation_data=validation_generator, callbacks=[early_stopping])\n",
    "test_loss_1, test_acc_1 = model_1.evaluate(validation_generator)\n",
    "print(f'Model 1 Accuracy: {test_acc_1}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "b02ecbd5-baff-4ec9-a612-08d5789bc2ca",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Entrenar y evaluar Modelo 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "a2823c18-a59d-490a-9d6b-437a05882d66",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "\u001b[1m81/81\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m76s\u001b[0m 806ms/step - accuracy: 0.2967 - loss: 1.6334 - val_accuracy: 0.5262 - val_loss: 1.1500\n",
      "Epoch 2/10\n",
      "\u001b[1m81/81\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m54s\u001b[0m 603ms/step - accuracy: 0.5831 - loss: 1.0690 - val_accuracy: 0.6212 - val_loss: 0.9162\n",
      "Epoch 3/10\n",
      "\u001b[1m81/81\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m43s\u001b[0m 515ms/step - accuracy: 0.6605 - loss: 0.8792 - val_accuracy: 0.7405 - val_loss: 0.7170\n",
      "\u001b[1m35/35\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 314ms/step - accuracy: 0.5252 - loss: 1.1776\n",
      "Model 2 Accuracy: 0.5262206196784973\n"
     ]
    }
   ],
   "source": [
    "model_2 = create_model_2()\n",
    "history_2 = model_2.fit(train_generator, epochs=10, validation_data=validation_generator, callbacks=[early_stopping])\n",
    "test_loss_2, test_acc_2 = model_2.evaluate(validation_generator)\n",
    "print(f'Model 2 Accuracy: {test_acc_2}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "e257725a-ad8d-413e-b362-8cb0038db6d8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Entrenar y evaluar Modelo 3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "566c3650-6cfa-42c6-9dd5-b26c072eaa78",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "\u001b[1m81/81\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m43s\u001b[0m 467ms/step - accuracy: 0.2377 - loss: 1.7111 - val_accuracy: 0.4819 - val_loss: 1.2795\n",
      "Epoch 2/10\n",
      "\u001b[1m81/81\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m43s\u001b[0m 488ms/step - accuracy: 0.4797 - loss: 1.3109 - val_accuracy: 0.5958 - val_loss: 0.9774\n",
      "Epoch 3/10\n",
      "\u001b[1m81/81\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m37s\u001b[0m 420ms/step - accuracy: 0.6157 - loss: 1.0126 - val_accuracy: 0.6881 - val_loss: 0.7848\n",
      "\u001b[1m35/35\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 247ms/step - accuracy: 0.4754 - loss: 1.2770\n",
      "Model 3 Accuracy: 0.4819168150424957\n"
     ]
    }
   ],
   "source": [
    "model_3 = create_model_3()\n",
    "history_3 = model_3.fit(train_generator, epochs=10, validation_data=validation_generator, callbacks=[early_stopping])\n",
    "test_loss_3, test_acc_3 = model_3.evaluate(validation_generator)\n",
    "print(f'Model 3 Accuracy: {test_acc_3}')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ffb53aad-0e66-4815-9bd6-732054dae32f",
   "metadata": {},
   "source": [
    "# Evaluacion del modelo\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "aa85b7ae-e502-4c86-8b02-3efee7f3cef9",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m50/50\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 175ms/step - accuracy: 0.8761 - loss: 0.4013\n",
      "Test accuracy: 0.876130223274231\n"
     ]
    }
   ],
   "source": [
    "test_loss, test_acc = model.evaluate(validation_generator, steps=50)\n",
    "print('Test accuracy:', test_acc)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "2cd7f6ab-fccb-44a7-8ea3-9cc1b2b3c9cb",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model 1 Accuracy: 0.4285714328289032\n",
      "Model 2 Accuracy: 0.5262206196784973\n",
      "Model 3 Accuracy: 0.4819168150424957\n"
     ]
    }
   ],
   "source": [
    "print(f'Model 1 Accuracy: {test_acc_1}')\n",
    "print(f'Model 2 Accuracy: {test_acc_2}')\n",
    "print(f'Model 3 Accuracy: {test_acc_3}')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0871ee19-e91c-4665-83d2-e1a07ab8bc04",
   "metadata": {},
   "source": [
    "# Conclucion"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "180dfc96-0a69-4cd7-9783-2b1236e9bde6",
   "metadata": {},
   "source": [
    "### Modelo 1, la arquitectura de este modelo es basicacon dos capas convolucionales es insuficiente para capturar los patrones necesarios y se obtinen la precisión más baja (42.9%).\n",
    "\n",
    "### Modelo 2, este modelo cuenta con tres capas convolucionales y mejora el rendimiento, alcanzando la mejor precisión (52.6%)\n",
    "\n",
    "### Modelo 3, este modeo incluye dropout para evitar los sobreajustes, aun asi su rendimiento es inferior al del Modelo 2 (48.2%)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "261843bf-ca65-4843-8637-1669ce1ad5c0",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
